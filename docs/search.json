[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GeoEpi Notebook",
    "section": "",
    "text": "The GeoEpi Research Group\nThe GeoEpi (Geographical Epidemiology) Group conducts research on animal disease transmission and outbreak dynamics. Using advanced statistical modeling, bioinformatics, and artificial intelligence, our work spans the molecular to landscape scales to reveal crucial insights into the ecology and management of foreign, transboundary, emerging, and zoonotic animal diseases."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n2 Stuff 1\n\n3 Stuff 2\n\n4 References\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "\n2  Summary\n",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html#the-geoepi-research-group",
    "href": "index.html#the-geoepi-research-group",
    "title": "GeoEpi Notebook",
    "section": "The GeoEpi Research Group",
    "text": "The GeoEpi Research Group\nThe GeoEpi Group investigates animal disease transmission and outbreak dynamics. Leveraging statistical and mathematical modeling, bioinformatics, and artificial intelligence, our work aims to bridge the molecular and landscape scales to reveal insights into the ecology and spatiotemporal dynamics of foreign, transboundary, emerging, and zoonotic animal diseases.\nThe GeoEpi Notebook is a resource designed for and by group members and collaborators engaged in geographical epidemiology and data science. Its purpose is to share and refine the best practices, standards, and guidelines essential for ensuring reproducible science across the domains of scientific computing, coding, data management, and modeling. Importantly, this notebook is envisioned as a living document—continually updated to reflect the latest insights, solutions, and efficiencies. It is not a compendium of rigid requirements but a collection of recommended approaches designed to enhance the quality and integrity of our work."
  },
  {
    "objectID": "start.html",
    "href": "start.html",
    "title": "Notebook Overview",
    "section": "",
    "text": "Notebook Overview"
  },
  {
    "objectID": "start.html#notebook-purpose-and-overview",
    "href": "start.html#notebook-purpose-and-overview",
    "title": "Notebook Overview",
    "section": "Notebook Purpose and Overview",
    "text": "Notebook Purpose and Overview"
  },
  {
    "objectID": "index.html#visit-the-geoepi-website-for-more-information",
    "href": "index.html#visit-the-geoepi-website-for-more-information",
    "title": "GeoEpi Notebook",
    "section": "Visit the GeoEpi website for more information",
    "text": "Visit the GeoEpi website for more information\n\n\n\nGeoEpi website"
  },
  {
    "objectID": "index.html#geoepi-research-group",
    "href": "index.html#geoepi-research-group",
    "title": "GeoEpi Notebook",
    "section": "GeoEpi Research Group",
    "text": "GeoEpi Research Group\nThe GeoEpi Group investigates animal disease transmission and outbreak dynamics. Leveraging statistical and mathematical modeling, bioinformatics, and artificial intelligence, our work aims to bridge the molecular and landscape scales to reveal insights into the ecology and spatiotemporal dynamics of foreign, transboundary, emerging, and zoonotic animal diseases.\nThe GeoEpi Notebook is a resource designed for and by group members and collaborators engaged in geographical epidemiology and data science. Its purpose is to share and refine the best practices, standards, and guidelines essential for ensuring reproducible science across the domains of scientific computing, coding, data management, and modeling. Importantly, this notebook is envisioned as a living document—continually updated to reflect the latest insights, solutions, and efficiencies. It is not a compendium of rigid requirements but a collection of recommended approaches designed to enhance the quality and integrity of our work."
  },
  {
    "objectID": "start.html#what-is-project-management",
    "href": "start.html#what-is-project-management",
    "title": "Project Management",
    "section": "What is project management?",
    "text": "What is project management?"
  },
  {
    "objectID": "proj_management.html#what-is-project-management",
    "href": "proj_management.html#what-is-project-management",
    "title": "Project Management",
    "section": "What is project management?",
    "text": "What is project management?"
  },
  {
    "objectID": "version_control.html",
    "href": "version_control.html",
    "title": "1  Version Control",
    "section": "",
    "text": "Version Control\nVersion control systems are indispensable tools in modern software development and scientific research. They offer a robust framework for tracking, collaborating, and managing changes to code and documents, thereby enhancing productivity, transparency, and reproducibility.\n\n1. Track Changes and History\nVersion control systems record every modification to the code. If a mistake is made, we can turn back the clock and compare earlier versions of the code to help fix the mistake.\n\n\n2. Collaboration\nAllows multiple people to work simultaneously on a single project. Each developer works independently, and their changes can be merged into a shared version.\n\n\n3. Branching and Merging\nIt supports branching, which lets scientists diverge from the main codebase but continue to work in parallel without affecting the core code. This is particularly useful for experimenting with new features or ideas in a sandboxed environment. Merging then allows these divergent branches to be recombined into the main project line, facilitating the integration of new features or fixes.\n\n\n4. Reproducibility\nVersion control is critical for reproducibility in scientific research. It allows researchers to access specific versions of scripts or analyses that produce particular results, ensuring that findings can be verified and built upon in future work.\n\n\n5. Backup\nWhile not a substitute for a full backup strategy, version control systems provide a safety net against code loss. By maintaining comprehensive histories of project files, they can protect against hardware failure, accidental deletions, and other mishaps.\n\n\n6. Undo Mistakes\nA significant benefit of version control is the ability to revert files or entire projects to a previous state, undo mistakes, and recover lost data. It provides a safety net that allows developers and researchers to experiment without fearing irrevocably breaking their work.\n\n\n7. Track Who Made Changes\nIn collaborative projects, version control helps identify which team members made specific changes or introduced issues. This aspect is crucial for coordinating team efforts and for historical understanding of project evolution.\n\n\n8. Documentation\nVersion control is documentation that shows the development process and decision-making over time. This can be invaluable for new team members learning the project or for external reviewers or collaborators seeking to understand its progression.\n\n\n\nWhat are Git and GitHub?\nGit is a version control system that enables users to track and manage changes to files and projects efficiently. GitHub is a hosting service that offers a web-based interface and additional tools for collaborative project management using Git software.\nGitHub has become the most popular platform for version control and collaborative software development. Its widespread adoption and utility in various fields, including scientific research, software engineering, and data science, can be attributed to several key features and benefits that make it an excellent choice for version control.\n\n1. User-Friendly Interface\nGitHub offers a web-based graphical interface that is intuitive for users at different levels of expertise. This accessibility lowers the barrier to entry for version control and makes it easier for users to manage repositories, track changes, and collaborate on projects without the need to master complex Git commands.\n\n\n2. Collaboration and Open Source\nGitHub is built to facilitate collaboration among researchers. It allows users to easily fork repositories, submit pull requests, and review code, making it an ideal platform for open-source science and collaborative team endeavors. ### 3. Integrated Issue Tracking GitHub provides integrated issue tracking that allows users to keep track of bugs, enhancements, and other project tasks. This feature seamlessly integrates with the codebase, enabling teams to manage and prioritize work efficiently alongside the development process.\n\n\n4. Continuous Integration and Deployment\nGitHub supports Continuous Integration and Continuous Deployment (CI/CD) processes through GitHub Actions. This allows developers to automate their build, test, and deployment workflows directly within their GitHub repositories, streamlining the development cycle and ensuring code integrity.\n\n\n5. Documentation\nWith GitHub, project documentation can be easily hosted alongside the codebase, for example, using markdown files and GitHub Pages.\n\n\n6. Security Features\nGitHub offers various security features to protect projects, including automated vulnerability scanning and alerts for repositories exposed to known security vulnerabilities in dependencies. This helps maintain the security integrity of projects hosted on the platform.\n\n\n7. Integration with External Tools\nGitHub integrates with many development tools and services, making it a versatile part of broader development ecosystems like Visual Studio Code, RStudio, and others\n\n\n8. Training and Resources\nGitHub offers a wealth of resources, including guides, tutorials, and community forums, that help users learn how to use Git and GitHub effectively.\n\n\n9. Team Organizations\nGitHub Organizations, like the GeoEpi GitHub Organization site, provide advanced options for team management, more granular access control, and enhanced security features, making them particularly useful for managing large, collaborative projects with multiple researchers."
  },
  {
    "objectID": "version_control.html#version-control",
    "href": "version_control.html#version-control",
    "title": "1  Version Control",
    "section": "Version Control",
    "text": "Version Control\nVersion control systems are indispensable tools in modern software development and scientific research. They offer a robust framework for tracking, collaborating, and managing changes to code and documents, thereby enhancing productivity, transparency, and reproducibility.\n\n1. Track Changes and History\nVersion control systems record every modification to the code. If a mistake is made, we can turn back the clock and compare earlier versions of the code to help fix the mistake.\n\n\n2. Collaboration\nAllows multiple people to work simultaneously on a single project. Each developer works independently, and their changes can be merged into a shared version.\n\n\n3. Branching and Merging\nIt supports branching, which lets scientists diverge from the main codebase but continue to work in parallel without affecting the core code. This is particularly useful for experimenting with new features or ideas in a sandboxed environment. Merging then allows these divergent branches to be recombined into the main project line, facilitating the integration of new features or fixes.\n\n\n4. Reproducibility\nVersion control is critical for reproducibility in scientific research. It allows researchers to access specific versions of scripts or analyses that produce particular results, ensuring that findings can be verified and built upon in future work.\n\n\n5. Backup\nWhile not a substitute for a full backup strategy, version control systems provide a safety net against code loss. By maintaining comprehensive histories of project files, they can protect against hardware failure, accidental deletions, and other mishaps.\n\n\n6. Undo Mistakes\nA significant benefit of version control is the ability to revert files or entire projects to a previous state, undo mistakes, and recover lost data. It provides a safety net that allows developers and researchers to experiment without fearing irrevocably breaking their work.\n\n\n7. Track Who Made Changes\nIn collaborative projects, version control helps identify which team members made specific changes or introduced issues. This aspect is crucial for coordinating team efforts and for historical understanding of project evolution.\n\n\n8. Documentation\nVersion control is documentation that shows the development process and decision-making over time. This can be invaluable for new team members learning the project or for external reviewers or collaborators seeking to understand its progression."
  },
  {
    "objectID": "version_control.html#what-are-git-and-github",
    "href": "version_control.html#what-are-git-and-github",
    "title": "1  Version Control",
    "section": "What are Git and GitHub?",
    "text": "What are Git and GitHub?\nGit is a version control system that enables users to track and manage changes to files and projects efficiently. GitHub is a hosting service that offers a web-based interface and additional tools for collaborative project management using Git software.\nGitHub has become the most popular platform for version control and collaborative software development. Its widespread adoption and utility in various fields, including scientific research, software engineering, and data science, can be attributed to several key features and benefits that make it an excellent choice for version control.\n\n1. User-Friendly Interface\nGitHub offers a web-based graphical interface that is intuitive for users at different levels of expertise. This accessibility lowers the barrier to entry for version control and makes it easier for users to manage repositories, track changes, and collaborate on projects without the need to master complex Git commands.\n\n\n2. Collaboration and Open Source\nGitHub is built to facilitate collaboration among researchers. It allows users to easily fork repositories, submit pull requests, and review code, making it an ideal platform for open-source science and collaborative team endeavors. ### 3. Integrated Issue Tracking GitHub provides integrated issue tracking that allows users to keep track of bugs, enhancements, and other project tasks. This feature seamlessly integrates with the codebase, enabling teams to manage and prioritize work efficiently alongside the development process.\n\n\n4. Continuous Integration and Deployment\nGitHub supports Continuous Integration and Continuous Deployment (CI/CD) processes through GitHub Actions. This allows developers to automate their build, test, and deployment workflows directly within their GitHub repositories, streamlining the development cycle and ensuring code integrity.\n\n\n5. Documentation\nWith GitHub, project documentation can be easily hosted alongside the codebase, for example, using markdown files and GitHub Pages.\n\n\n6. Security Features\nGitHub offers various security features to protect projects, including automated vulnerability scanning and alerts for repositories exposed to known security vulnerabilities in dependencies. This helps maintain the security integrity of projects hosted on the platform.\n\n\n7. Integration with External Tools\nGitHub integrates with many development tools and services, making it a versatile part of broader development ecosystems like Visual Studio Code, RStudio, and others\n\n\n8. Training and Resources\nGitHub offers a wealth of resources, including guides, tutorials, and community forums, that help users learn how to use Git and GitHub effectively.\n\n\n9. Team Organizations\nGitHub Organizations, like the GeoEpi GitHub Organization site, provide advanced options for team management, more granular access control, and enhanced security features, making them particularly useful for managing large, collaborative projects with multiple researchers."
  },
  {
    "objectID": "github_elements.html#github-elements",
    "href": "github_elements.html#github-elements",
    "title": "2  GitHub Elements",
    "section": "GitHub Elements",
    "text": "GitHub Elements\nEssential steps in collaborative code development with GitHub\nElement 1: Introduction to GitHub and its Importance in Scientific Computing\n- Overview of GitHub\n- Importance of version control in software development\n- Role of GitHub in collaborative research and development\n- GitHub’s impact on reproducibility and transparency in science\nElement 2: Setting Up and Navigating GitHub\n- Creating a GitHub account\n- Overview of the GitHub interface\n- Key terminology (repository, branch, commit, pull request, merge, etc.)\nElement 3: Creating and Cloning Repositories\n- Introduction to repositories\n- How to create a new repository\n- Initializing a repository with README, .gitignore, and license\n- Cloning a repository to your local machine\nElement 4: Branches and Commits\n- The concept of branches in version control\n- Creating and switching between branches\n- Making changes and committing them to a branch\nElement 5: Pull Requests and Code Reviews\n- The purpose of pull requests in collaborative development\n- Creating a pull request\n- Reviewing pull requests from collaborators\n- Best practices for code reviews\nElement 6: Merging Pull Requests and Resolving Conflicts\n- The merge process explained\n- Handling merge conflicts\n- Strategies for successful merges"
  },
  {
    "objectID": "github_elements.html",
    "href": "github_elements.html",
    "title": "2  GitHub Elements",
    "section": "",
    "text": "GitHub Elements\nThe below outline served as an agenda for group GitHub training conducted in early 2024. It can be considered a checklist for GitHub tasks that everyone should be able to perform.\nElement 1: Introduction to GitHub and its Importance in Scientific Computing\n- Overview of GitHub\n- Importance of version control in software development\n- Role of GitHub in collaborative research and development\n- GitHub’s impact on reproducibility and transparency in science\nElement 2: Setting Up and Navigating GitHub\n- Creating a GitHub account\n- Overview of the GitHub interface\n- Key terminology (repository, branch, commit, pull request, merge, etc.)\nElement 3: Creating and Cloning Repositories\n- Introduction to repositories\n- How to create a new repository\n- Initializing a repository with README, .gitignore, and license\n- Cloning a repository to your local machine\nElement 4: Branches and Commits\n- The concept of branches in version control\n- Creating and switching between branches\n- Making changes and committing them to a branch\nElement 5: Pull Requests and Code Reviews\n- The purpose of pull requests in collaborative development\n- Creating a pull request\n- Reviewing pull requests from collaborators\n- Best practices for code reviews\nElement 6: Merging Pull Requests and Resolving Conflicts\n- The merge process - Handling merge conflicts\n- Strategies for successful merges"
  },
  {
    "objectID": "proj_management.html",
    "href": "proj_management.html",
    "title": "Project Management",
    "section": "",
    "text": "What is a project?\nA project is any concerted or individual effort to produce a product. Products may be as simple as a single coded function made by an individual or as complex as an entire workflow or pipeline developed over multiple years by a dozen different scientists. In general, anytime documents, code, and data are brought together for a targeted purpose, it’s a project!\nProject management is the process of organizing a project’s documents, code, and data to ensure open science and reproducibility. In quantitative, model-based research, open science and reproducibility are foundational principles that aim to enhance the credibility, utility, and ethical standards of scientific inquiry.\n\nOpen Science\nOpen science refers to making scientific research processes, data, and outputs accessible to all levels of the public, amateur, professional, and non-scientists. It encompasses various practices aimed at making research more transparent and collaborative. In quantitative, model-based research, open science can be characterized by:\n- Open Data: Sharing the raw and processed data used in analyses, underpinned by the principle that data should be as open as possible. In cases where raw data cannot be provided due to the inclusion of personally identifying information or proprietary constraints, simulated data should be made available.\n- Open Methodology: Detailing the research methods, including models, algorithms, and statistical techniques, to allow for critical examination and replication of the research.\n- Open Source Software: Releasing the software, codebase, or scripts developed for the research thereby facilitating reuse, adaptation, and scrutiny by others.\n\n\nReproducibility\nReproducibility is the ability to replicate the outcomes of a study based on the original data and methods used in the research. In quantitative, model-based disciplines, reproducibility signifies that independent researchers can use the same data and computational procedures to achieve consistent results. Reproducibility involves several key aspects:\n- Data Reproducibility: Ensuring that the data used in research are available and accessible, allowing others to use them in replicating the study.\n- Analytical Reproducibility: Providing clear, detailed descriptions of models, analytical methods, and computational processes so that they can be precisely followed and reproduced.\n- Computational Reproducibility: Sharing the exact versions of software, libraries, and environments used in the research to eliminate discrepancies due to software updates or platform differences.\n\n\nImplications and Importance\n\nCredibility: Open science and reproducibility practices enhance the credibility of research findings by subjecting them to broader scrutiny and verification.\n\nInnovation: By sharing data, methods, and tools, researchers can build on existing work, fostering innovation and accelerating scientific discovery.\n\nEfficiency: Open practices prevent the duplication of effort, as researchers can use and extend existing datasets and models rather than starting from scratch.\n\nTransparency: Transparency in the research process helps identify potential biases, errors, or assumptions inherent in quantitative models.\n\nEthical Research Practice: Open science aligns with ethical principles by ensuring that scientific knowledge is a public good, accessible to all and not just a privileged few."
  },
  {
    "objectID": "repo_components.html",
    "href": "repo_components.html",
    "title": "3  GH Repo Components",
    "section": "",
    "text": "Essential GitHub Repository Components\nCore structure, files, directories suggested for a GitHub repository, aka a Repo. The below text describes items that should be included in project repos. These are general suggestions, individual projects will have different needs, and different project leads will have different preferences.\n\n1. Private or Public?\n\nOK to keep private while under development, but must ensure that all collaborators have access.\n\nUltimately, everything should be public, practice project management and documentation with this in mind.\n\n\n\n2. Strongly Suggested (mandatory?)\n\nA README.md to describe contents and purpose.\nA .gitignore to indicate which files on your machine should not be copied to GitHub\n\nA secrets.yaml to keep copies of passwords for API accounts and collaborative repos when you’re not the admin. Make sure the secrets file is included in the .gitignore!\nA /local or /private directory for un-shared data and local, preliminary work. Make sure the secrets file is included in the .gitignore!\n\n\n\n3. Suggested\n\nlicense\nA tests/ directory\nA dedicated directory for coded functions, (e.g., a /R or similar)\nA docs/ directory for templates, webpage htmls, etc.\nA src/ directory for source code (if developing a package or library)\n\nA vignettes/ or demos/ directory for examples, scripts, and demonstration of code in the functions directory."
  },
  {
    "objectID": "openscifw.html",
    "href": "openscifw.html",
    "title": "4  Data Storage (OSF)",
    "section": "",
    "text": "Open Science Framework (OSF)\nData storage and management using the Open Science Framework (OSF)…"
  },
  {
    "objectID": "overleaf.html",
    "href": "overleaf.html",
    "title": "5  LaTeX and Overleaf",
    "section": "",
    "text": "LaTeX and Overleaf\nManuscript drafting and documentation using LaTeX, particularly through the collaborative platform Overleaf, is the best choice for crafting scientific manuscripts and technical documents that require mathematical notation and complex formatting. Overleaf facilitates seamless collaboration, allowing multiple authors to edit documents simultaneously and track changes efficiently with integrated version control. Moreover, Overleaf’s compatibility with GitHub enhances workflow integration, enabling code and document synchronization, while its support for reference management software like Zotero simplifies article and citation management."
  },
  {
    "objectID": "data_store.html",
    "href": "data_store.html",
    "title": "4  Data Storage",
    "section": "",
    "text": "Where should data be saved?\nIn the course of a research project, data storage requirements evolve significantly. During the initial phases, especially in early model development, data must be readily accessible across various computing environments—from individual researcher laptops to high-performance computing systems—ensuring that all team members can access necessary information seamlessly. As projects approach completion, the focus shifts towards making select datasets publicly available, ensuring proper archival, and adhering to open science principles. Additionally, storage solutions must account for the data composition, such as personally identifiable information (PII) or proprietary content, which might dictate more stringent access and security measures. Furthermore, data shared by collaborators might come with restrictions that limit access exclusively to specific project members, adding another layer of complexity to data management.\nBelow are some preferred options to consider.\n\n\nSCINet\nDuring active model development, the Agricultural Research Service’s SCINet is likely the best option for storage and group access to big data. If the project only requires tens of megabytes, then several other options may work equally as well, but once the 100mb threshold is reached, SCINet may be the best choice.\nIf you’re a member of the GeoEpi group, a storage allotment has probably already been reserved for your project. If storage hasn’t already been set aside for a project, more space is needed, extra security is needed, or additional project members need to be given access, discuss this with the project’s lead.\nOnce the need for SCINet storage has been identified, consider the optimal place to store the data:\n- Atlas or Ceres Clusters: Project directories can be used for short term storage of preprocessed data that’s ready to be analyzed.\n- 90DayData storage: For short-term storage of large data. Best for really large data (remote sensing, land cover, etc), prior to processing. Will automatically be wiped after 90days.\n- Juno: Long-term Storage of multi-petabyte data at the National Agricultural Library in Maryland.\nWhere NOT to store data on SCINet: The home directory of your individual user account. Your individual account only provides about 10gb of storage. This should be adequate for configuration files and custom software not found on the shared systems, but not anything more.\n\n\nOpen Science Framework (OSF)\nData storage and management using the Open Science Framework (OSF) may be a good option. OSF is free for individual file sizes up to 80gb, uses duel authentication, and provides numerous security options for controlling access among project team members and the public. OSF data can be accessed remotely using an API, which may make it more accessible for project members that don’t have, or wouldn’t otherwise need a SCINet account. The OSF interface may also be a little more intuitive to project members that aren’t trained in data science. It is important to keep in mind that not all project members are data scientists, some are veterinarians, bench microbiologists, virologists, entomologists, field epidemiologist, wildlife managers, and similar experts don’t routinely use code or command line tools. It’s often necessary to share or receive data or metadata with these team members, OSF may be simpler for them too navigate than SCINet.\n\n\nData Archiving\nWith very few and rare exceptions, all projects that are funded through the USDA, or include a USDA employee as part of the project team, will need to archive data at some point to provide long term public access. At a minimum, this means data will be stored in a permanent and publicly accessible location and be assigned a DOI (Digital Object Identifier) that links to an online document that records deposition of the data and includes a permanent web address (URL) to locate it.\nIn addition to commonly used services, like Zenodo, and data-type specific storage providers (e.g., GenBank for genetic data), there are a couple other options to consider.\n- Ag Data Commons at the National Agricultural Library which serves as a repository for public access to data produced during research funded or co-funded by the USDA.\n- Open Science Framework (OSF) offers DOI generation and archiving. Although OSF is a relative newcomer as an archiving service, the ability to archive as an addition to the other tools services provides for project management make it somewhat of a one stop shop for the entire research lifecycle.\n\n\nWhat about GitHub?\nAlthough GitHub is a great service for managing a codebase, and even integrates with Zenodo for archiving, it is not intended or appropriate for, data storage. Observation data, data other than code or small data used in vignettes or demos, should be stored elsewhere."
  },
  {
    "objectID": "zotero.html",
    "href": "zotero.html",
    "title": "6  Reference Management",
    "section": "",
    "text": "Group Zotero Libraries\n\nFoot and Mouth Disease (FMD)\n\nFeral Swine\nFlavivirus\n\nVesicular stomatitis"
  }
]